# -*- coding: utf-8 -*-
import os
import argparse
import logging
import sys
import time
import json
import re
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, date
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import List, Dict, Any, Optional

from config import get_config, Config
from storage import get_db
from data_provider import DataFetcherManager
from analyzer import GeminiAnalyzer, AnalysisResult
from notification import NotificationService

# ================= æ—¥å¿—é…ç½® =================

LOG_FORMAT = '%(asctime)s | %(levelname)-8s | %(name)-20s | %(message)s'
LOG_DATE_FORMAT = '%Y-%m-%d %H:%M:%S'
DEFAULT_SECTOR = "Macro"

def setup_logging(debug: bool = False, log_dir: str = "./logs") -> None:
    log_path = Path(log_dir)
    log_path.mkdir(parents=True, exist_ok=True)

    today_str = datetime.now().strftime('%Y%m%d')
    log_file = log_path / f"stock_analysis_{today_str}.log"

    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG if debug else logging.INFO)
    root_logger.handlers = []

    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(console_handler)

    file_handler = RotatingFileHandler(
        log_file, maxBytes=10 * 1024 * 1024, backupCount=5, encoding='utf-8'
    )
    file_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(file_handler)

logger = logging.getLogger(__name__)

# ================= Pipeline =================

class StockAnalysisPipeline:
    def __init__(self, config: Optional[Config] = None, max_workers: Optional[int] = None):
        self.config = config or get_config()

        env_workers = os.getenv("MAX_CONCURRENT")
        # å¼ºåˆ¶é»˜è®¤å•çº¿ç¨‹ï¼Œé¿å…è§¦å‘ Gemini å…è´¹ç‰ˆ API é€Ÿç‡é™åˆ¶ (429)
        self.max_workers = int(env_workers) if env_workers else 1

        self.portfolio = self._load_portfolio_config()
        self.db = get_db()
        self.fetcher_manager = DataFetcherManager()
        self.analyzer = GeminiAnalyzer()
        self.notifier = NotificationService()

        logger.info(f"AI-CIO åˆå§‹åŒ–å®Œæˆ | å¹¶å‘æ•°={self.max_workers}")

    # ---------- é…ç½®åŠ è½½ï¼ˆå…¼å®¹ List å’Œ Dictï¼‰ ----------

    def _load_portfolio_config(self) -> dict:
        """
        è¯»å– portfolio.jsonï¼Œå¹¶ç¡®ä¿è¿”å›å­—å…¸æ ¼å¼ã€‚
        å³ä½¿ JSON é‡Œæ²¡æœ‰ nameï¼Œåç»­ä¹Ÿä¼šè‡ªåŠ¨å¡«å……ã€‚
        """
        path = "portfolio.json"
        if not os.path.exists(path):
            return {}
        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
                
                # æƒ…å†µA: æ—§ç‰ˆåˆ—è¡¨æ ¼å¼ ["600519"]
                if isinstance(data, list):
                    return {
                        str(code): {
                            "code": str(code), 
                            "cost": 0, 
                            "shares": 0, 
                            "name": f"è‚¡ç¥¨{code}",  # ä¸´æ—¶åï¼Œç¨åä¼šè¢«è¦†ç›–
                            "sector": "Unknown"
                        } 
                        for code in data
                    }
                
                # æƒ…å†µB: æ–°ç‰ˆå­—å…¸æ ¼å¼
                if isinstance(data, dict):
                    final_data = {}
                    for code, info in data.items():
                        if not isinstance(info, dict):
                            info = {}
                        
                        info["code"] = str(code)
                        info.setdefault("cost", 0)
                        info.setdefault("shares", 0)
                        # è¿™é‡Œç»™ä¸ªé»˜è®¤åï¼Œé˜²æ­¢ process_single_stock é‡Œè·å–å¤±è´¥æ—¶æŠ¥é”™
                        info.setdefault("name", f"è‚¡ç¥¨{code}") 
                        info.setdefault("sector", "Unknown")
                        
                        final_data[str(code)] = info
                    return final_data
                
                return {}
                
        except Exception as e:
            logger.error(f"åŠ è½½ portfolio.json å¤±è´¥: {e}")
            return {}

    # ---------- æ–°é—»ä¸Šä¸‹æ–‡ ----------

    def _get_trend_radar_context(self, code: str, json_path: str = "news_summary.json") -> dict:
        context = {"macro": "", "sector": "", "target_sector": DEFAULT_SECTOR}
        stock_info = self.portfolio.get(code, {})
        target_sector = stock_info.get("sector", DEFAULT_SECTOR)
        context["target_sector"] = target_sector

        if not os.path.exists(json_path):
            return context

        try:
            with open(json_path, "r", encoding="utf-8") as f:
                news_items = json.load(f)

            macro_news, sector_news = [], []
            for item in news_items:
                cat = item.get("category", "Macro")
                line = f"- {item.get('title', '')}: {item.get('summary', '')}"
                if cat in ["Macro", "Finance"]:
                    macro_news.append(line)
                if cat == target_sector:
                    sector_news.append(line)

            context["macro"] = "\n".join(macro_news) if macro_news else "å½“å‰å®è§‚é¢å¹³é™ã€‚"
            context["sector"] = (
                "\n".join(sector_news) if sector_news else f"å½“å‰{target_sector}æ¿å—æ— é‡å¤§æ¶ˆæ¯ã€‚"
            )
            return context
        except Exception as e:
            logger.warning(f"è¯»å–æ–°é—»ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return context

    # ---------- æŠ€æœ¯æŒ‡æ ‡ ----------

    def _calculate_technical_indicators(self, df: pd.DataFrame) -> dict:
        if df is None or df.empty:
            return {}

        try:
            df = df.sort_values("date")
            close = df["close"]

            ma5 = close.rolling(5).mean().iloc[-1]
            ma20 = close.rolling(20).mean().iloc[-1]
            ma60 = close.rolling(60).mean().iloc[-1]

            delta = close.diff()
            gain = delta.where(delta > 0, 0).rolling(14).mean()
            loss = -delta.where(delta < 0, 0).rolling(14).mean()
            
            if loss.iloc[-1] == 0:
                rsi = 100
            else:
                rs = gain / loss
                rsi = 100 - (100 / (1 + rs)).iloc[-1]

            exp12 = close.ewm(span=12, adjust=False).mean()
            exp26 = close.ewm(span=26, adjust=False).mean()
            macd = (exp12 - exp26).iloc[-1]
            signal = (exp12 - exp26).ewm(span=9, adjust=False).mean().iloc[-1]

            return {
                "price": close.iloc[-1],
                "ma5": ma5,
                "ma20": ma20,
                "ma60": ma60,
                "rsi": rsi,
                "macd": macd,
                "macd_signal": signal,
                "support": df["low"].tail(20).min(),
                "resistance": df["high"].tail(20).max(),
            }
        except Exception as e:
            logger.warning(f"æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
            return {}

    # ---------- æ•°æ®æŠ“å– ----------

    def fetch_and_save_stock_data(self, code: str) -> Optional[pd.DataFrame]:
        try:
            df, source = self.fetcher_manager.get_daily_data(code, days=100)
            if df is not None and not df.empty:
                self.db.save_daily_data(df, code, source)
                return df
            return None
        except Exception as e:
            logger.error(f"[{code}] è¡Œæƒ…æŠ“å–å¤±è´¥: {e}")
            return None

    # ---------- å•è‚¡å¤„ç† (å…³é”®ä¿®æ”¹ï¼šè‡ªåŠ¨æå–åç§°) ----------

    def process_single_stock(self, code: str, dry_run: bool = False) -> Optional[AnalysisResult]:
        # 1. æå–6ä½æ•°å­—ä»£ç 
        match = re.search(r"\d{6}", code)
        if not match:
            return None

        stock_code = match.group(0)
        logger.info(f"========== å¤„ç† A è‚¡: {stock_code} ==========")

        try:
            time.sleep(2)  # è½»é‡é™æµ

            # 2. è·å–è¡Œæƒ…æ•°æ®
            df = self.fetch_and_save_stock_data(stock_code)
            if df is None or df.empty:
                logger.error(f"[{stock_code}] æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡åˆ†æ")
                return None

            if dry_run:
                logger.info(f"[{stock_code}] dry-run æ¨¡å¼ï¼Œè·³è¿‡ AI åˆ†æ")
                return None

            # 3. å‡†å¤‡ä¸Šä¸‹æ–‡ (åŒ…å«æŒä»“ä¿¡æ¯)
            default_name = f"è‚¡ç¥¨{stock_code}"
            stock_info = self.portfolio.get(
                stock_code, 
                {"name": default_name, "sector": DEFAULT_SECTOR, "cost": 0, "shares": 0}
            )
            stock_info.setdefault("code", stock_code)

            # === ğŸŸ¢ è‡ªåŠ¨è¡¥å…¨åç§°é€»è¾‘ ===
            # Efinance æ•°æ®æºé€šå¸¸åŒ…å« "è‚¡ç¥¨åç§°" åˆ—
            if "è‚¡ç¥¨åç§°" in df.columns:
                real_name = str(df.iloc[-1]["è‚¡ç¥¨åç§°"])
                # å¦‚æœå½“å‰é…ç½®çš„åå­—æ˜¯é»˜è®¤çš„(è‚¡ç¥¨xxxx)æˆ–ç©ºçš„ï¼Œå°±ç”¨æŠ“å–åˆ°çš„çœŸåè¦†ç›–
                if stock_info.get("name") == default_name or not stock_info.get("name"):
                    logger.info(f"[{stock_code}] è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨åç§°: {real_name}")
                    stock_info["name"] = real_name
            # =========================

            # 4. è®¡ç®—æŒ‡æ ‡ä¸å‡†å¤‡ Prompt
            tech_data = self._calculate_technical_indicators(df)
            trend_context = self._get_trend_radar_context(stock_code)

            # ç”Ÿæˆ Prompt (æ­¤æ—¶ stock_info['name'] å·²ç»æ˜¯çœŸåäº†)
            prompt = self.analyzer.generate_cio_prompt(stock_info, tech_data, trend_context)

            context = {
                "code": stock_code,
                "stock_name": stock_info.get("name", stock_code),
                "date": date.today().strftime("%Y-%m-%d"),
            }

            # 5. è°ƒç”¨ AI
            result = self.analyzer.analyze(context, custom_prompt=prompt)
            if result is None:
                logger.error(f"[{stock_code}] AI è¿”å›ä¸ºç©ºï¼Œå·²ä¸¢å¼ƒ")
                return None

            logger.info(f"[{stock_code}] AI åˆ†æå®Œæˆ")
            return result

        except Exception as e:
            logger.exception(f"[{stock_code}] å¤„ç†å¼‚å¸¸: {e}")
            return None

    # ---------- ä¸»æ‰§è¡Œ ----------

    def run(
        self,
        stock_codes: Optional[List[str]] = None,
        dry_run: bool = False,
        send_notification: bool = True,
    ) -> List[AnalysisResult]:

        if stock_codes is None:
            stock_codes = list(self.portfolio.keys()) if self.portfolio else []
            if not stock_codes:
                stock_list_env = self.config.stock_list
                if stock_list_env:
                    stock_codes = [s.strip() for s in stock_list_env.split(",")]

        results: List[AnalysisResult] = []

        logger.info(f"å¼€å§‹åˆ†æä»»åŠ¡ï¼Œç›®æ ‡åˆ—è¡¨: {stock_codes}")

        # ğŸŸ¢ å…³é”®ä¿®æ”¹ï¼šå–æ¶ˆå¹¶å‘ï¼Œæ”¹ä¸ºä¸²è¡Œæ‰§è¡Œï¼Œå¹¶å¢åŠ å¼ºåˆ¶å†·å´æ—¶é—´
        # å³ä½¿ max_workers=1ï¼Œä½¿ç”¨ ThreadPool è¿˜æ˜¯ä¸å¦‚ç›´æ¥ for å¾ªç¯å®¹æ˜“æ§åˆ¶ sleep
        for i, code in enumerate(stock_codes):
            try:
                res = self.process_single_stock(code, dry_run)
                if res:
                    results.append(res)
                
                # ğŸŸ¢ å¼ºåˆ¶å†·å´ï¼šé™¤äº†æœ€åä¸€ä¸ªï¼Œæ¯è·‘å®Œä¸€ä¸ªä¼‘æ¯ 15 ç§’ï¼Œé˜²æ­¢ 429 æŠ¥é”™
                if i < len(stock_codes) - 1:
                    logger.info("â³ è§¦å‘ API å†·å´ä¿æŠ¤ï¼Œç­‰å¾… 15 ç§’...")
                    time.sleep(15)

            except Exception as e:
                logger.exception(f"å¤„ç† {code} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

        if results and send_notification and not dry_run:
            try:
                report = self.notifier.generate_dashboard_report(results)
                if self.notifier.is_available():
                    self.notifier.send_to_telegram(report)
            except Exception as e:
                logger.exception(f"å‘é€é€šçŸ¥å¤±è´¥ï¼Œä½†ä¸å½±å“æµç¨‹: {e}")

        logger.info(f"æœ¬æ¬¡è¿è¡Œå®Œæˆ | æˆåŠŸåˆ†æ {len(results)} åªè‚¡ç¥¨")
        return results

# ================= CLI =================

def parse_arguments():
    parser = argparse.ArgumentParser(description="AI-CIO")
    parser.add_argument("--debug", action="store_true")
    parser.add_argument("--dry-run", action="store_true", help="ä»…æŠ“å–æ•°æ®ï¼Œä¸è¿›è¡Œ AI åˆ†æ")
    parser.add_argument("--stocks", type=str)
    parser.add_argument("--no-notify", action="store_true")
    parser.add_argument("--workers", type=int)
    parser.add_argument("--market-review", action="store_true", help="ä»…è¿è¡Œå¤§ç›˜å¤ç›˜")
    return parser.parse_args()

def main():
    args = parse_arguments()
    config = get_config()
    setup_logging(args.debug, config.log_dir)

    if args.market_review:
        logger.info("å½“å‰æ¨¡å¼ä¸ºå¤§ç›˜å¤ç›˜ (Market Review)ï¼Œæš‚æœªå®ç°å…·ä½“é€»è¾‘ï¼Œè·³è¿‡ã€‚")
        return 0

    stock_list = [s.strip() for s in args.stocks.split(",")] if args.stocks else None

    # å¼ºåˆ¶ä½¿ç”¨å•çº¿ç¨‹é€»è¾‘ (max_workers=1 å…¶å®åœ¨ç±»åˆå§‹åŒ–æ—¶å·²å¤„ç†ï¼Œè¿™é‡Œåªæ˜¯å½¢å¼)
    pipeline = StockAnalysisPipeline(config, max_workers=1)
    pipeline.run(
        stock_codes=stock_list,
        dry_run=args.dry_run,
        send_notification=not args.no_notify,
    )
    return 0

if __name__ == "__main__":
    sys.exit(main())
